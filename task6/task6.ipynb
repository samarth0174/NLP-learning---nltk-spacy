{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance OF Stemmers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# porterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do any stemmers use any lexicons to stemm?\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmerporter = PorterStemmer()\n",
    "stemmerporter.stem('running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regexStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runn'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regexStemmer\n",
    "import nltk\n",
    "from nltk.stem import RegexpStemmer\n",
    "reg = RegexpStemmer('ing')\n",
    "reg.stem('running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do any stemmers use any lexicons to stemm?\n",
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster=LancasterStemmer()\n",
    "lancaster.stem('running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appoint'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SnowballStemmer\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "SnowballStemmer.languages\n",
    "frenchstemmer = SnowballStemmer('english')\n",
    "frenchstemmer.stem('appointment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#no of languagess snowball support ---> 16\n",
    "#SnowBall performs well compared to other stemmers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique example where only regexstem works\n",
    "Consider an example where we are only interested in the stem 'make' and from  word 'maker' we need to extract the stem. Lets try it with the above stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is 'maker'\n",
      "PorterStemmer ans: maker\n",
      "RegexStemmer ans: make\n",
      "lancaster ans: mak\n",
      "Snowball ans: maker\n",
      "Thus in above case RegexStemmer performs better than other Stemmers\n"
     ]
    }
   ],
   "source": [
    "print(\"Word is 'maker'\")\n",
    "#porter stemmer\n",
    "print(\"PorterStemmer ans:\",stemmerporter.stem('maker'))\n",
    "#regex stemmer\n",
    "reg = RegexpStemmer('[$r|$s]')\n",
    "print(\"RegexStemmer ans:\" , reg.stem('maker'))\n",
    "#lancasterStemmer\n",
    "print(\"lancaster ans:\",lancaster.stem('maker'))\n",
    "#SnowballStemmer\n",
    "stt = SnowballStemmer('english')\n",
    "print(\"Snowball ans:\",stt.stem('maker'))\n",
    "\n",
    "print(\"Thus in above case RegexStemmer performs better than other Stemmers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lemmatizer - find lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "better : good\n",
      "unhappy : unhappy\n",
      "running: run\n"
     ]
    }
   ],
   "source": [
    "#lemmatizer - find lemma\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "\n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) \n",
    "print(\"unhappy :\", lemmatizer.lemmatize(\"unhappy\")) \n",
    "print(\"running:\", lemmatizer.lemmatize(\"running\",pos=\"v\")) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemmer Vs Lemmatizer\n",
    "Lemmatisation is closely related to stemming. The difference is that a stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words which have different meanings depending on part of speech. However, stemmers are typically easier to implement and run faster, and the reduced accuracy may not matter for some applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quick brown fox jump over a lazi dog\n",
      "A quick brown fox jump over a lazy dog\n"
     ]
    }
   ],
   "source": [
    "#Stem a Paragraph\n",
    "stemmer = PorterStemmer()\n",
    "example = \"A quick brown fox jumps over a lazy dog\"\n",
    "example = [stemmer.stem(token)for token in example.split(\" \")]\n",
    "print(\" \".join(example))\n",
    "\n",
    "#Lemattize a paragraph \n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "example1 = \"A quick brown fox jumps over a lazy dog\"\n",
    "example1 = [lemmatizer.lemmatize(token)for token in example1.split(\" \")]\n",
    "print(\" \".join(example1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Above example shows that lemmatizer works better than stemm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECTORIZERS - Count Vectorizers\n",
    "CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = ['This is the first document.','This document is the second document.', 'And this is the third one.',\n",
    "'Is this the first document?']\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using TF.IDF.VECTORIZER -> Normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glove - the  vectorizer from Stanford"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
